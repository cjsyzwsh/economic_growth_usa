{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f232ed5",
   "metadata": {},
   "source": [
    "# GCN prediction \n",
    "\n",
    "- Not used in the current draft.\n",
    "- Demonstrate the importance of width and depth.\n",
    "- Demonstrate the predictive power of weak mobility ties, as opposed to spatial and strong ties.\n",
    "- Test the robustness by varying other GCN components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bc6cf3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key text.latex.preview in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 125 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 157 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 420 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 493 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 504 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file /home/jtl/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 506 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# GNN packages\n",
    "# Question: How to use a virtual environment in a jupyter notebook? Mine does not work yet.\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, Linear, GATConv, SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f040a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adf158d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '../utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd95f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "with open(\"../../data/02_intermediate/greater_boston_ct_shp.pickle\", 'rb') as f:\n",
    "    df_shp = pickle.load(f)\n",
    "\n",
    "with open(\"../../data/03_processed/greater_boston_ct_socioecon_shp.pickle\", 'rb') as f:\n",
    "    df_socioecon_shp = pickle.load(f)\n",
    "    \n",
    "with open(\"../../data/02_intermediate/boston_stays.pickle\", 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "with open(\"../../data/03_processed/A_home_activity_unweighted_dic.pickle\", 'rb') as f:\n",
    "    A_home_activity_unweighted_dic = pickle.load(f)\n",
    "\n",
    "with open(\"../../data/03_processed/A_home_activity_weighted_dic.pickle\", 'rb') as f:\n",
    "    A_home_activity_weighted_dic = pickle.load(f)\n",
    "    \n",
    "with open(\"../../data/05_model_outputs/lasso_coefficients.pickle\", 'rb') as f:\n",
    "    lasso_coef = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "284a88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/03_processed/spatial_network_dic.pickle\", 'rb') as f:\n",
    "    spatial_network_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdef0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "with open(\"../../data/03_processed/A_home_total_unweighted_dic.pickle\", 'rb') as f:\n",
    "    A_home_total_unweighted_dic = pickle.load(f)\n",
    "\n",
    "with open(\"../../data/03_processed/A_home_total_weighted_dic.pickle\", 'rb') as f:\n",
    "    A_home_total_weighted_dic = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f62851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boston_queen_contiguity_adj_df', 'boston_rook_contiguity_adj_df', 'boston_5nn_contiguity_adj_df', 'county_adj_df'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_network_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18cb4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "['Caribbean', 'Latin American', 'Spanish', 'Auto Garage', 'Fried Chicken', 'Poutine Place', 'Fishing Store', 'Meze Restaurants', 'Food Stand', 'Watch Shops', 'Tapas', 'Peking Duck', 'Drugstore', 'Juice Bar', 'Salad', 'Cycle Studio', 'New American', 'French']\n"
     ]
    }
   ],
   "source": [
    "# get the significant activities\n",
    "sig_activities = list(lasso_coef['inc_per_capita_2018']['lasso (no socio-demographics)'].index)\n",
    "print(len(sig_activities))\n",
    "print(sig_activities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc207c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of activity categories 633\n",
      "Top 20 large-quantity mobility ties:  ['Office', 'Residential', 'Building', 'Automotive', 'Church', 'Salon / Barbershop', \"Doctor's Office\", 'Pizza', 'American', 'Gas Station', 'Gym', 'Road', 'Bank', 'Donuts', 'Hardware', 'Grocery Store', 'Supermarket', 'Bar', \"Dentist's Office\", 'Convenience Store']\n"
     ]
    }
   ],
   "source": [
    "# get the overall activity ranking\n",
    "activity_counts = np.unique(df.cat, return_counts = True)\n",
    "print(\"Total number of activity categories\", len(activity_counts[0]))\n",
    "\n",
    "# \n",
    "activity_count_df = pd.DataFrame(activity_counts[1],\n",
    "                                 index = activity_counts[0],\n",
    "                                 columns = ['count'])\n",
    "sorted_activity_count_df = activity_count_df.sort_values('count', ascending=False)\n",
    "# \n",
    "print(\"Top 20 large-quantity mobility ties: \", list(activity_count_df.sort_values('count', ascending=False).index[:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9600ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init performance\n",
    "gcn_performance_dic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f92f5",
   "metadata": {},
   "source": [
    "# Node-only GCN without edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34996c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the baseline regressions\n",
    "input_vars = ['pop_total_2016',\n",
    "              'pop_density_2016',\n",
    "              'age_median_2016', \n",
    "              'household_size_avg_2016',\n",
    "              'sex_male_ratio_2016', \n",
    "              'race_white_ratio_2016',\n",
    "              'edu_bachelor_ratio_2016',\n",
    "              'edu_master_ratio_2016',\n",
    "              'edu_master_ratio_2016', \n",
    "              'vehicle_per_capita_2016']\n",
    "\n",
    "# predict inc_per_capita_2018\n",
    "output_var = 'inc_per_capita_2018'\n",
    "\n",
    "\n",
    "X = normalize(df_socioecon_shp[input_vars].values, axis = 0)\n",
    "y = normalize(df_socioecon_shp[output_var].values.reshape(-1, 1), axis = 0).reshape(-1, 1)\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "\n",
    "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = \\\n",
    "    train_test_split(X_tensor, y_tensor, test_size = 0.33, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e4d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup: device, model, inputs and outputs.\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = Linear(10, 1, bias = True).to(device)\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# X_tensor = X_tensor.to(device)\n",
    "# y_tensor = y_tensor.to(device)\n",
    "# optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7441e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_loss(output, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - output) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4058307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fun\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X_train_tensor)\n",
    "    loss = F.mse_loss(out, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()   \n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15540ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fun\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    train_pred = model(X_train_tensor)\n",
    "    test_pred = model(X_test_tensor)\n",
    "    \n",
    "    train_mse = F.mse_loss(train_pred, y_train_tensor)\n",
    "    test_mse = F.mse_loss(test_pred, y_test_tensor)\n",
    "    train_r2 = r2_loss(train_pred, y_train_tensor)\n",
    "    test_r2 = r2_loss(test_pred, y_test_tensor)\n",
    "    return train_mse, test_mse, train_r2, test_r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2824cabb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train Loss: 0.000081, Train R2: 0.5289, Test R2: 0.1795\n",
      "Epoch: 200, Train Loss: 0.000073, Train R2: 0.5783, Test R2: 0.3153\n",
      "Epoch: 300, Train Loss: 0.000067, Train R2: 0.6095, Test R2: 0.4010\n",
      "Epoch: 400, Train Loss: 0.000064, Train R2: 0.6298, Test R2: 0.4549\n",
      "Epoch: 500, Train Loss: 0.000061, Train R2: 0.6451, Test R2: 0.4903\n",
      "Epoch: 600, Train Loss: 0.000059, Train R2: 0.6578, Test R2: 0.5151\n",
      "Epoch: 700, Train Loss: 0.000057, Train R2: 0.6685, Test R2: 0.5335\n",
      "Epoch: 800, Train Loss: 0.000056, Train R2: 0.6772, Test R2: 0.5473\n",
      "Epoch: 900, Train Loss: 0.000054, Train R2: 0.6842, Test R2: 0.5576\n",
      "Epoch: 1000, Train Loss: 0.000054, Train R2: 0.6895, Test R2: 0.5653\n",
      "Epoch: 1100, Train Loss: 0.000053, Train R2: 0.6935, Test R2: 0.5708\n",
      "Epoch: 1200, Train Loss: 0.000052, Train R2: 0.6965, Test R2: 0.5746\n",
      "Epoch: 1300, Train Loss: 0.000052, Train R2: 0.6987, Test R2: 0.5773\n",
      "Epoch: 1400, Train Loss: 0.000052, Train R2: 0.7002, Test R2: 0.5791\n",
      "Epoch: 1500, Train Loss: 0.000051, Train R2: 0.7014, Test R2: 0.5805\n",
      "Epoch: 1600, Train Loss: 0.000051, Train R2: 0.7022, Test R2: 0.5815\n",
      "Epoch: 1700, Train Loss: 0.000051, Train R2: 0.7029, Test R2: 0.5823\n",
      "Epoch: 1800, Train Loss: 0.000051, Train R2: 0.7035, Test R2: 0.5830\n",
      "Epoch: 1900, Train Loss: 0.000051, Train R2: 0.7040, Test R2: 0.5837\n",
      "Epoch: 2000, Train Loss: 0.000051, Train R2: 0.7044, Test R2: 0.5845\n",
      "Epoch: 2100, Train Loss: 0.000051, Train R2: 0.7048, Test R2: 0.5852\n",
      "Epoch: 2200, Train Loss: 0.000051, Train R2: 0.7052, Test R2: 0.5859\n",
      "Epoch: 2300, Train Loss: 0.000051, Train R2: 0.7056, Test R2: 0.5865\n",
      "Epoch: 2400, Train Loss: 0.000051, Train R2: 0.7059, Test R2: 0.5872\n",
      "Epoch: 2500, Train Loss: 0.000051, Train R2: 0.7062, Test R2: 0.5879\n",
      "Epoch: 2600, Train Loss: 0.000051, Train R2: 0.7065, Test R2: 0.5885\n",
      "Epoch: 2700, Train Loss: 0.000051, Train R2: 0.7067, Test R2: 0.5890\n",
      "Epoch: 2800, Train Loss: 0.000050, Train R2: 0.7070, Test R2: 0.5896\n",
      "Epoch: 2900, Train Loss: 0.000050, Train R2: 0.7072, Test R2: 0.5900\n",
      "Epoch: 3000, Train Loss: 0.000050, Train R2: 0.7074, Test R2: 0.5905\n",
      "Epoch: 3100, Train Loss: 0.000050, Train R2: 0.7075, Test R2: 0.5908\n",
      "Epoch: 3200, Train Loss: 0.000050, Train R2: 0.7077, Test R2: 0.5912\n",
      "Epoch: 3300, Train Loss: 0.000050, Train R2: 0.7078, Test R2: 0.5915\n",
      "Epoch: 3400, Train Loss: 0.000050, Train R2: 0.7080, Test R2: 0.5917\n",
      "Epoch: 3500, Train Loss: 0.000050, Train R2: 0.7081, Test R2: 0.5920\n",
      "Epoch: 3600, Train Loss: 0.000050, Train R2: 0.7082, Test R2: 0.5921\n",
      "Epoch: 3700, Train Loss: 0.000050, Train R2: 0.7083, Test R2: 0.5923\n",
      "Epoch: 3800, Train Loss: 0.000050, Train R2: 0.7083, Test R2: 0.5924\n",
      "Epoch: 3900, Train Loss: 0.000050, Train R2: 0.7084, Test R2: 0.5924\n",
      "Epoch: 4000, Train Loss: 0.000050, Train R2: 0.7085, Test R2: 0.5925\n",
      "Epoch: 4100, Train Loss: 0.000050, Train R2: 0.7085, Test R2: 0.5925\n",
      "Epoch: 4200, Train Loss: 0.000050, Train R2: 0.7086, Test R2: 0.5925\n",
      "Epoch: 4300, Train Loss: 0.000050, Train R2: 0.7086, Test R2: 0.5925\n",
      "Epoch: 4400, Train Loss: 0.000050, Train R2: 0.7086, Test R2: 0.5924\n",
      "Epoch: 4500, Train Loss: 0.000050, Train R2: 0.7087, Test R2: 0.5924\n",
      "Epoch: 4600, Train Loss: 0.000050, Train R2: 0.7087, Test R2: 0.5923\n",
      "Epoch: 4700, Train Loss: 0.000050, Train R2: 0.7087, Test R2: 0.5922\n",
      "Epoch: 4800, Train Loss: 0.000050, Train R2: 0.7088, Test R2: 0.5921\n",
      "Epoch: 4900, Train Loss: 0.000050, Train R2: 0.7088, Test R2: 0.5919\n",
      "Epoch: 5000, Train Loss: 0.000050, Train R2: 0.7088, Test R2: 0.5918\n",
      "Epoch: 5100, Train Loss: 0.000050, Train R2: 0.7088, Test R2: 0.5917\n",
      "Epoch: 5200, Train Loss: 0.000050, Train R2: 0.7088, Test R2: 0.5915\n",
      "Epoch: 5300, Train Loss: 0.000050, Train R2: 0.7088, Test R2: 0.5914\n",
      "Epoch: 5400, Train Loss: 0.000050, Train R2: 0.7088, Test R2: 0.5913\n",
      "Epoch: 5500, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5911\n",
      "Epoch: 5600, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5910\n",
      "Epoch: 5700, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5909\n",
      "Epoch: 5800, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5907\n",
      "Epoch: 5900, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5906\n",
      "Epoch: 6000, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5905\n",
      "Epoch: 6100, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5904\n",
      "Epoch: 6200, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5903\n",
      "Epoch: 6300, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5902\n",
      "Epoch: 6400, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5901\n",
      "Epoch: 6500, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5901\n",
      "Epoch: 6600, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5900\n",
      "Epoch: 6700, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5899\n",
      "Epoch: 6800, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5899\n",
      "Epoch: 6900, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5898\n",
      "Epoch: 7000, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5898\n",
      "Epoch: 7100, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5898\n",
      "Epoch: 7200, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5898\n",
      "Epoch: 7300, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 7400, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 7500, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 7600, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 7700, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 7800, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 7900, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 8000, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 8100, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 8200, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 8300, Train Loss: 0.000050, Train R2: 0.7075, Test R2: 0.5745\n",
      "Epoch: 8400, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5896\n",
      "Epoch: 8500, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 8600, Train Loss: 0.000050, Train R2: 0.7074, Test R2: 0.6015\n",
      "Epoch: 8700, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5896\n",
      "Epoch: 8800, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 8900, Train Loss: 0.000052, Train R2: 0.6993, Test R2: 0.5411\n",
      "Epoch: 9000, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5896\n",
      "Epoch: 9100, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 9200, Train Loss: 0.000050, Train R2: 0.7077, Test R2: 0.5757\n",
      "Epoch: 9300, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5894\n",
      "Epoch: 9400, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 9500, Train Loss: 0.000051, Train R2: 0.7049, Test R2: 0.5616\n",
      "Epoch: 9600, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5895\n",
      "Epoch: 9700, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5897\n",
      "Epoch: 9800, Train Loss: 0.000050, Train R2: 0.7086, Test R2: 0.5953\n",
      "Epoch: 9900, Train Loss: 0.000050, Train R2: 0.7089, Test R2: 0.5898\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 10000\n",
    "for epoch in range(1, epochs):\n",
    "    loss = train()\n",
    "    train_mse, test_mse, train_r2, test_r2 = test() \n",
    "    if epoch%100 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Loss: {train_mse:.6f}, Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90020d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node-only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>0.708898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.589662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          node-only\n",
       "training   0.708898\n",
       "testing    0.589662"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the performance\n",
    "gcn_performance_dic['node-only'] = pd.DataFrame([train_r2.cpu(), test_r2.cpu()], \n",
    "                                                index = ['training', 'testing'],\n",
    "                                                columns = ['node-only'])\n",
    "gcn_performance_dic['node-only']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb6967",
   "metadata": {},
   "source": [
    "# GCN (Depth = 1): spatial, aggregate, strong, and weak networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed412d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the baseline regressions\n",
    "input_vars = ['pop_total_2016',\n",
    "              'pop_density_2016',\n",
    "              'age_median_2016', \n",
    "              'household_size_avg_2016',\n",
    "              'sex_male_ratio_2016', \n",
    "              'race_white_ratio_2016',\n",
    "              'edu_bachelor_ratio_2016',\n",
    "              'edu_master_ratio_2016',\n",
    "              'edu_master_ratio_2016', \n",
    "              'vehicle_per_capita_2016']\n",
    "\n",
    "# predict inc_per_capita_2018\n",
    "output_var = 'inc_per_capita_2018'\n",
    "\n",
    "X = normalize(df_socioecon_shp[input_vars].values, axis = 0)\n",
    "y = normalize(df_socioecon_shp[output_var].values.reshape(-1, 1), axis = 0).reshape(-1, 1)\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fad1d0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(682)\n",
      "tensor(310)\n"
     ]
    }
   ],
   "source": [
    "# creating the train and test masks\n",
    "np.random.seed(seed = 42)\n",
    "train_mask = np.random.choice([True, False], X_tensor.size()[0], p = [0.67,0.33]) #.reshape(-1, 1)\n",
    "test_mask = ~train_mask\n",
    "train_mask_tensor = torch.from_numpy(train_mask)\n",
    "test_mask_tensor = torch.from_numpy(test_mask)\n",
    "\n",
    "print(train_mask_tensor.sum())\n",
    "print(test_mask_tensor.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f66623aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with the simplest case.\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 1, bias = True)\n",
    "        self.lin1 = Linear(-1, 1, bias = True)\n",
    "\n",
    "    def forward(self):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "#         print(x, edge_index)\n",
    "        x = self.conv1(x, edge_index) + self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c6de779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 definition\n",
    "def r2_loss(output, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - output) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f80964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model.forward()[data['train_mask']]\n",
    "    loss = F.mse_loss(out, data.y[data['train_mask']])\n",
    "    loss.backward()\n",
    "    optimizer.step()   \n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c868377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    train_pred = model.forward()[data['train_mask']]\n",
    "    test_pred = model.forward()[data['test_mask']]\n",
    "    \n",
    "    train_mse = F.mse_loss(train_pred, data.y[data['train_mask']])\n",
    "    test_mse = F.mse_loss(test_pred, data.y[data['test_mask']])\n",
    "    train_r2 = r2_loss(train_pred, data.y[data['train_mask']])\n",
    "    test_r2 = r2_loss(test_pred, data.y[data['test_mask']])    \n",
    "    return train_mse, test_mse, train_r2, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f514ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test four adj matrices\n",
    "# note that the four matrices are quite simple examples. \n",
    "\n",
    "A_dic = {}\n",
    "A_dic['spatial'] = utils.turn_df_to_adj(spatial_network_dic['boston_queen_contiguity_adj_df'], df_shp)\n",
    "A_dic['spatial'] = A_dic['spatial'].values\n",
    "A_dic['aggregate'] = utils.turn_df_to_adj(A_home_total_unweighted_dic[1.0]['total'], df_shp)\n",
    "A_dic['aggregate'] = A_dic['aggregate'].values\n",
    "A_dic['strong'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['Office'], df_shp)\n",
    "A_dic['strong'] = A_dic['strong'].values\n",
    "A_dic['weak'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['New American'], df_shp)\n",
    "A_dic['weak'] = A_dic['weak'].values\n",
    "\n",
    "# A = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['New American'], df_shp)\n",
    "# A = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['Office'], df_shp)\n",
    "# A = utils.turn_df_to_adj(spatial_network_dic['boston_queen_contiguity_adj_df'], df_shp)\n",
    "# A = utils.turn_df_to_adj(A_home_total_unweighted_dic[1.0]['total'], df_shp)\n",
    "# A = A.values\n",
    "\n",
    "A_data_dic = {}\n",
    "\n",
    "for key_ in A_dic.keys():\n",
    "    A = A_dic[key_]\n",
    "    # create the list of edges\n",
    "    row_idx = csr_matrix(A).tocoo().row\n",
    "    col_idx = csr_matrix(A).tocoo().col\n",
    "    data_idx = csr_matrix(A).tocoo().data\n",
    "\n",
    "    # edge index\n",
    "    edge_index = torch.tensor([list(row_idx)+list(col_idx), list(col_idx)+list(row_idx)], dtype = torch.long)\n",
    "\n",
    "    # init data\n",
    "    data = Data(edge_index=edge_index, x = X_tensor, y = y_tensor, \n",
    "                train_mask = train_mask_tensor, \n",
    "                test_mask = test_mask_tensor)\n",
    "    \n",
    "    A_data_dic[key_] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e920d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance table\n",
    "gcn_performance_one_layer_df = pd.DataFrame(np.zeros((2, 4)), \n",
    "                                            index = ['training', 'testing'], \n",
    "                                            columns = list(A_dic.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83eb2371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train Loss: 0.000265, Train R2: -0.7716, Test R2: -0.6748\n",
      "Epoch: 200, Train Loss: 0.000203, Train R2: -0.3559, Test R2: -0.3032\n",
      "Epoch: 300, Train Loss: 0.000164, Train R2: -0.0946, Test R2: -0.0661\n",
      "Epoch: 400, Train Loss: 0.000131, Train R2: 0.1219, Test R2: 0.1281\n",
      "Epoch: 500, Train Loss: 0.000106, Train R2: 0.2935, Test R2: 0.2784\n",
      "Epoch: 600, Train Loss: 0.000087, Train R2: 0.4211, Test R2: 0.3881\n",
      "Epoch: 700, Train Loss: 0.000073, Train R2: 0.5114, Test R2: 0.4648\n",
      "Epoch: 800, Train Loss: 0.000064, Train R2: 0.5729, Test R2: 0.5169\n",
      "Epoch: 900, Train Loss: 0.000058, Train R2: 0.6138, Test R2: 0.5517\n",
      "Epoch: 1000, Train Loss: 0.000054, Train R2: 0.6408, Test R2: 0.5752\n",
      "Epoch: 1100, Train Loss: 0.000051, Train R2: 0.6590, Test R2: 0.5914\n",
      "Epoch: 1200, Train Loss: 0.000049, Train R2: 0.6716, Test R2: 0.6033\n",
      "Epoch: 1300, Train Loss: 0.000048, Train R2: 0.6809, Test R2: 0.6126\n",
      "Epoch: 1400, Train Loss: 0.000047, Train R2: 0.6880, Test R2: 0.6201\n",
      "Epoch: 1500, Train Loss: 0.000046, Train R2: 0.6938, Test R2: 0.6266\n",
      "Epoch: 1600, Train Loss: 0.000045, Train R2: 0.6986, Test R2: 0.6323\n",
      "Epoch: 1700, Train Loss: 0.000044, Train R2: 0.7028, Test R2: 0.6374\n",
      "Epoch: 1800, Train Loss: 0.000044, Train R2: 0.7064, Test R2: 0.6420\n",
      "Epoch: 1900, Train Loss: 0.000043, Train R2: 0.7097, Test R2: 0.6462\n",
      "Epoch: 2000, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6501\n",
      "Epoch: 2100, Train Loss: 0.000043, Train R2: 0.7152, Test R2: 0.6536\n",
      "Epoch: 2200, Train Loss: 0.000042, Train R2: 0.7176, Test R2: 0.6569\n",
      "Epoch: 2300, Train Loss: 0.000042, Train R2: 0.7197, Test R2: 0.6598\n",
      "Epoch: 2400, Train Loss: 0.000042, Train R2: 0.7217, Test R2: 0.6625\n",
      "Epoch: 2500, Train Loss: 0.000041, Train R2: 0.7234, Test R2: 0.6649\n",
      "Epoch: 2600, Train Loss: 0.000041, Train R2: 0.7249, Test R2: 0.6671\n",
      "Epoch: 2700, Train Loss: 0.000041, Train R2: 0.7262, Test R2: 0.6690\n",
      "Epoch: 2800, Train Loss: 0.000041, Train R2: 0.7274, Test R2: 0.6708\n",
      "Epoch: 2900, Train Loss: 0.000041, Train R2: 0.7285, Test R2: 0.6723\n",
      "Epoch: 3000, Train Loss: 0.000040, Train R2: 0.7294, Test R2: 0.6737\n",
      "Epoch: 3100, Train Loss: 0.000040, Train R2: 0.7302, Test R2: 0.6749\n",
      "Epoch: 3200, Train Loss: 0.000040, Train R2: 0.7308, Test R2: 0.6759\n",
      "Epoch: 3300, Train Loss: 0.000040, Train R2: 0.7314, Test R2: 0.6768\n",
      "Epoch: 3400, Train Loss: 0.000040, Train R2: 0.7319, Test R2: 0.6776\n",
      "Epoch: 3500, Train Loss: 0.000040, Train R2: 0.7323, Test R2: 0.6783\n",
      "Epoch: 3600, Train Loss: 0.000040, Train R2: 0.7327, Test R2: 0.6789\n",
      "Epoch: 3700, Train Loss: 0.000040, Train R2: 0.7330, Test R2: 0.6794\n",
      "Epoch: 3800, Train Loss: 0.000040, Train R2: 0.7333, Test R2: 0.6798\n",
      "Epoch: 3900, Train Loss: 0.000040, Train R2: 0.7335, Test R2: 0.6802\n",
      "Epoch: 4000, Train Loss: 0.000040, Train R2: 0.7337, Test R2: 0.6806\n",
      "Epoch: 4100, Train Loss: 0.000040, Train R2: 0.7338, Test R2: 0.6809\n",
      "Epoch: 4200, Train Loss: 0.000040, Train R2: 0.7340, Test R2: 0.6811\n",
      "Epoch: 4300, Train Loss: 0.000040, Train R2: 0.7341, Test R2: 0.6814\n",
      "Epoch: 4400, Train Loss: 0.000040, Train R2: 0.7342, Test R2: 0.6816\n",
      "Epoch: 4500, Train Loss: 0.000040, Train R2: 0.7343, Test R2: 0.6818\n",
      "Epoch: 4600, Train Loss: 0.000040, Train R2: 0.7344, Test R2: 0.6820\n",
      "Epoch: 4700, Train Loss: 0.000040, Train R2: 0.7345, Test R2: 0.6821\n",
      "Epoch: 4800, Train Loss: 0.000040, Train R2: 0.7346, Test R2: 0.6823\n",
      "Epoch: 4900, Train Loss: 0.000040, Train R2: 0.7346, Test R2: 0.6824\n",
      "Epoch: 5000, Train Loss: 0.000040, Train R2: 0.7347, Test R2: 0.6826\n",
      "Epoch: 5100, Train Loss: 0.000040, Train R2: 0.7347, Test R2: 0.6827\n",
      "Epoch: 5200, Train Loss: 0.000040, Train R2: 0.7348, Test R2: 0.6828\n",
      "Epoch: 5300, Train Loss: 0.000040, Train R2: 0.7348, Test R2: 0.6829\n",
      "Epoch: 5400, Train Loss: 0.000040, Train R2: 0.7349, Test R2: 0.6830\n",
      "Epoch: 5500, Train Loss: 0.000040, Train R2: 0.7349, Test R2: 0.6831\n",
      "Epoch: 5600, Train Loss: 0.000040, Train R2: 0.7349, Test R2: 0.6832\n",
      "Epoch: 5700, Train Loss: 0.000040, Train R2: 0.7350, Test R2: 0.6833\n",
      "Epoch: 5800, Train Loss: 0.000040, Train R2: 0.7350, Test R2: 0.6833\n",
      "Epoch: 5900, Train Loss: 0.000040, Train R2: 0.7350, Test R2: 0.6834\n",
      "Epoch: 6000, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6834\n",
      "Epoch: 6100, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6835\n",
      "Epoch: 6200, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6835\n",
      "Epoch: 6300, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6836\n",
      "Epoch: 6400, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6836\n",
      "Epoch: 6500, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6836\n",
      "Epoch: 6600, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 6700, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 6800, Train Loss: 0.000040, Train R2: 0.7334, Test R2: 0.6786\n",
      "Epoch: 6900, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 7000, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6837\n",
      "Epoch: 7100, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 7200, Train Loss: 0.000040, Train R2: 0.7350, Test R2: 0.6845\n",
      "Epoch: 7300, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 7400, Train Loss: 0.000040, Train R2: 0.7349, Test R2: 0.6848\n",
      "Epoch: 7500, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6837\n",
      "Epoch: 7600, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 7700, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6829\n",
      "Epoch: 7800, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6833\n",
      "Epoch: 7900, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 8000, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6831\n",
      "Epoch: 8100, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6833\n",
      "Epoch: 8200, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 8300, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6836\n",
      "Epoch: 8400, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6829\n",
      "Epoch: 8500, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 8600, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 8700, Train Loss: 0.000040, Train R2: 0.7346, Test R2: 0.6850\n",
      "Epoch: 8800, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 8900, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 9000, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6829\n",
      "Epoch: 9100, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 9200, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 9300, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6839\n",
      "Epoch: 9400, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 9500, Train Loss: 0.000040, Train R2: 0.7351, Test R2: 0.6825\n",
      "Epoch: 9600, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6833\n",
      "Epoch: 9700, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 9800, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6835\n",
      "Epoch: 9900, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6830\n",
      "Epoch: 100, Train Loss: 0.000104, Train R2: 0.3036, Test R2: 0.4267\n",
      "Epoch: 200, Train Loss: 0.000081, Train R2: 0.4563, Test R2: 0.5159\n",
      "Epoch: 300, Train Loss: 0.000070, Train R2: 0.5304, Test R2: 0.5517\n",
      "Epoch: 400, Train Loss: 0.000064, Train R2: 0.5736, Test R2: 0.5692\n",
      "Epoch: 500, Train Loss: 0.000060, Train R2: 0.6016, Test R2: 0.5795\n",
      "Epoch: 600, Train Loss: 0.000057, Train R2: 0.6217, Test R2: 0.5874\n",
      "Epoch: 700, Train Loss: 0.000054, Train R2: 0.6371, Test R2: 0.5945\n",
      "Epoch: 800, Train Loss: 0.000052, Train R2: 0.6496, Test R2: 0.6012\n",
      "Epoch: 900, Train Loss: 0.000051, Train R2: 0.6599, Test R2: 0.6073\n",
      "Epoch: 1000, Train Loss: 0.000050, Train R2: 0.6686, Test R2: 0.6127\n",
      "Epoch: 1100, Train Loss: 0.000048, Train R2: 0.6760, Test R2: 0.6176\n",
      "Epoch: 1200, Train Loss: 0.000047, Train R2: 0.6823, Test R2: 0.6219\n",
      "Epoch: 1300, Train Loss: 0.000047, Train R2: 0.6876, Test R2: 0.6256\n",
      "Epoch: 1400, Train Loss: 0.000046, Train R2: 0.6921, Test R2: 0.6288\n",
      "Epoch: 1500, Train Loss: 0.000045, Train R2: 0.6958, Test R2: 0.6315\n",
      "Epoch: 1600, Train Loss: 0.000045, Train R2: 0.6989, Test R2: 0.6339\n",
      "Epoch: 1700, Train Loss: 0.000045, Train R2: 0.7014, Test R2: 0.6358\n",
      "Epoch: 1800, Train Loss: 0.000044, Train R2: 0.7034, Test R2: 0.6374\n",
      "Epoch: 1900, Train Loss: 0.000044, Train R2: 0.7051, Test R2: 0.6387\n",
      "Epoch: 2000, Train Loss: 0.000044, Train R2: 0.7064, Test R2: 0.6397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2100, Train Loss: 0.000044, Train R2: 0.7074, Test R2: 0.6405\n",
      "Epoch: 2200, Train Loss: 0.000044, Train R2: 0.7083, Test R2: 0.6412\n",
      "Epoch: 2300, Train Loss: 0.000044, Train R2: 0.7089, Test R2: 0.6417\n",
      "Epoch: 2400, Train Loss: 0.000043, Train R2: 0.7094, Test R2: 0.6421\n",
      "Epoch: 2500, Train Loss: 0.000043, Train R2: 0.7098, Test R2: 0.6424\n",
      "Epoch: 2600, Train Loss: 0.000043, Train R2: 0.7101, Test R2: 0.6427\n",
      "Epoch: 2700, Train Loss: 0.000043, Train R2: 0.7103, Test R2: 0.6429\n",
      "Epoch: 2800, Train Loss: 0.000043, Train R2: 0.7105, Test R2: 0.6430\n",
      "Epoch: 2900, Train Loss: 0.000043, Train R2: 0.7107, Test R2: 0.6431\n",
      "Epoch: 3000, Train Loss: 0.000043, Train R2: 0.7108, Test R2: 0.6432\n",
      "Epoch: 3100, Train Loss: 0.000043, Train R2: 0.7109, Test R2: 0.6433\n",
      "Epoch: 3200, Train Loss: 0.000043, Train R2: 0.7110, Test R2: 0.6433\n",
      "Epoch: 3300, Train Loss: 0.000043, Train R2: 0.7111, Test R2: 0.6434\n",
      "Epoch: 3400, Train Loss: 0.000043, Train R2: 0.7112, Test R2: 0.6434\n",
      "Epoch: 3500, Train Loss: 0.000043, Train R2: 0.7112, Test R2: 0.6434\n",
      "Epoch: 3600, Train Loss: 0.000043, Train R2: 0.7113, Test R2: 0.6434\n",
      "Epoch: 3700, Train Loss: 0.000043, Train R2: 0.7113, Test R2: 0.6434\n",
      "Epoch: 3800, Train Loss: 0.000043, Train R2: 0.7114, Test R2: 0.6434\n",
      "Epoch: 3900, Train Loss: 0.000043, Train R2: 0.7114, Test R2: 0.6434\n",
      "Epoch: 4000, Train Loss: 0.000043, Train R2: 0.7114, Test R2: 0.6434\n",
      "Epoch: 4100, Train Loss: 0.000043, Train R2: 0.7115, Test R2: 0.6434\n",
      "Epoch: 4200, Train Loss: 0.000043, Train R2: 0.7115, Test R2: 0.6434\n",
      "Epoch: 4300, Train Loss: 0.000043, Train R2: 0.7115, Test R2: 0.6434\n",
      "Epoch: 4400, Train Loss: 0.000043, Train R2: 0.7116, Test R2: 0.6434\n",
      "Epoch: 4500, Train Loss: 0.000043, Train R2: 0.7116, Test R2: 0.6434\n",
      "Epoch: 4600, Train Loss: 0.000043, Train R2: 0.7116, Test R2: 0.6434\n",
      "Epoch: 4700, Train Loss: 0.000043, Train R2: 0.7116, Test R2: 0.6435\n",
      "Epoch: 4800, Train Loss: 0.000043, Train R2: 0.7117, Test R2: 0.6435\n",
      "Epoch: 4900, Train Loss: 0.000043, Train R2: 0.7117, Test R2: 0.6435\n",
      "Epoch: 5000, Train Loss: 0.000043, Train R2: 0.7117, Test R2: 0.6435\n",
      "Epoch: 5100, Train Loss: 0.000043, Train R2: 0.7117, Test R2: 0.6435\n",
      "Epoch: 5200, Train Loss: 0.000043, Train R2: 0.7117, Test R2: 0.6441\n",
      "Epoch: 5300, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6439\n",
      "Epoch: 5400, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6436\n",
      "Epoch: 5500, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6435\n",
      "Epoch: 5600, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6439\n",
      "Epoch: 5700, Train Loss: 0.000043, Train R2: 0.7119, Test R2: 0.6437\n",
      "Epoch: 5800, Train Loss: 0.000043, Train R2: 0.7119, Test R2: 0.6436\n",
      "Epoch: 5900, Train Loss: 0.000043, Train R2: 0.7119, Test R2: 0.6442\n",
      "Epoch: 6000, Train Loss: 0.000043, Train R2: 0.7119, Test R2: 0.6438\n",
      "Epoch: 6100, Train Loss: 0.000043, Train R2: 0.7120, Test R2: 0.6438\n",
      "Epoch: 6200, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6448\n",
      "Epoch: 6300, Train Loss: 0.000043, Train R2: 0.7120, Test R2: 0.6438\n",
      "Epoch: 6400, Train Loss: 0.000043, Train R2: 0.7120, Test R2: 0.6439\n",
      "Epoch: 6500, Train Loss: 0.000053, Train R2: 0.6480, Test R2: 0.6099\n",
      "Epoch: 6600, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6440\n",
      "Epoch: 6700, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6439\n",
      "Epoch: 6800, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6440\n",
      "Epoch: 6900, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6444\n",
      "Epoch: 7000, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6440\n",
      "Epoch: 7100, Train Loss: 0.000043, Train R2: 0.7122, Test R2: 0.6440\n",
      "Epoch: 7200, Train Loss: 0.000044, Train R2: 0.7083, Test R2: 0.6461\n",
      "Epoch: 7300, Train Loss: 0.000043, Train R2: 0.7122, Test R2: 0.6441\n",
      "Epoch: 7400, Train Loss: 0.000043, Train R2: 0.7122, Test R2: 0.6441\n",
      "Epoch: 7500, Train Loss: 0.000046, Train R2: 0.6948, Test R2: 0.6404\n",
      "Epoch: 7600, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6442\n",
      "Epoch: 7700, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6441\n",
      "Epoch: 7800, Train Loss: 0.000053, Train R2: 0.6441, Test R2: 0.6074\n",
      "Epoch: 7900, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6442\n",
      "Epoch: 8000, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6442\n",
      "Epoch: 8100, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6442\n",
      "Epoch: 8200, Train Loss: 0.000043, Train R2: 0.7124, Test R2: 0.6443\n",
      "Epoch: 8300, Train Loss: 0.000043, Train R2: 0.7124, Test R2: 0.6443\n",
      "Epoch: 8400, Train Loss: 0.000043, Train R2: 0.7124, Test R2: 0.6443\n",
      "Epoch: 8500, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6431\n",
      "Epoch: 8600, Train Loss: 0.000043, Train R2: 0.7124, Test R2: 0.6443\n",
      "Epoch: 8700, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6443\n",
      "Epoch: 8800, Train Loss: 0.000043, Train R2: 0.7119, Test R2: 0.6418\n",
      "Epoch: 8900, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6444\n",
      "Epoch: 9000, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6444\n",
      "Epoch: 9100, Train Loss: 0.000045, Train R2: 0.6957, Test R2: 0.6184\n",
      "Epoch: 9200, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6445\n",
      "Epoch: 9300, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6445\n",
      "Epoch: 9400, Train Loss: 0.000049, Train R2: 0.6699, Test R2: 0.6252\n",
      "Epoch: 9500, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6444\n",
      "Epoch: 9600, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6445\n",
      "Epoch: 9700, Train Loss: 0.000047, Train R2: 0.6860, Test R2: 0.6355\n",
      "Epoch: 9800, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6444\n",
      "Epoch: 9900, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6446\n",
      "Epoch: 100, Train Loss: 0.000082, Train R2: 0.4511, Test R2: 0.4392\n",
      "Epoch: 200, Train Loss: 0.000063, Train R2: 0.5769, Test R2: 0.5323\n",
      "Epoch: 300, Train Loss: 0.000057, Train R2: 0.6207, Test R2: 0.5706\n",
      "Epoch: 400, Train Loss: 0.000053, Train R2: 0.6485, Test R2: 0.5984\n",
      "Epoch: 500, Train Loss: 0.000050, Train R2: 0.6670, Test R2: 0.6185\n",
      "Epoch: 600, Train Loss: 0.000048, Train R2: 0.6795, Test R2: 0.6329\n",
      "Epoch: 700, Train Loss: 0.000047, Train R2: 0.6881, Test R2: 0.6428\n",
      "Epoch: 800, Train Loss: 0.000046, Train R2: 0.6940, Test R2: 0.6496\n",
      "Epoch: 900, Train Loss: 0.000045, Train R2: 0.6979, Test R2: 0.6542\n",
      "Epoch: 1000, Train Loss: 0.000045, Train R2: 0.7006, Test R2: 0.6572\n",
      "Epoch: 1100, Train Loss: 0.000044, Train R2: 0.7024, Test R2: 0.6593\n",
      "Epoch: 1200, Train Loss: 0.000044, Train R2: 0.7037, Test R2: 0.6607\n",
      "Epoch: 1300, Train Loss: 0.000044, Train R2: 0.7046, Test R2: 0.6616\n",
      "Epoch: 1400, Train Loss: 0.000044, Train R2: 0.7052, Test R2: 0.6623\n",
      "Epoch: 1500, Train Loss: 0.000044, Train R2: 0.7057, Test R2: 0.6628\n",
      "Epoch: 1600, Train Loss: 0.000044, Train R2: 0.7061, Test R2: 0.6631\n",
      "Epoch: 1700, Train Loss: 0.000044, Train R2: 0.7064, Test R2: 0.6634\n",
      "Epoch: 1800, Train Loss: 0.000044, Train R2: 0.7068, Test R2: 0.6636\n",
      "Epoch: 1900, Train Loss: 0.000044, Train R2: 0.7071, Test R2: 0.6637\n",
      "Epoch: 2000, Train Loss: 0.000044, Train R2: 0.7073, Test R2: 0.6638\n",
      "Epoch: 2100, Train Loss: 0.000044, Train R2: 0.7076, Test R2: 0.6639\n",
      "Epoch: 2200, Train Loss: 0.000044, Train R2: 0.7078, Test R2: 0.6639\n",
      "Epoch: 2300, Train Loss: 0.000044, Train R2: 0.7081, Test R2: 0.6640\n",
      "Epoch: 2400, Train Loss: 0.000044, Train R2: 0.7083, Test R2: 0.6640\n",
      "Epoch: 2500, Train Loss: 0.000044, Train R2: 0.7085, Test R2: 0.6640\n",
      "Epoch: 2600, Train Loss: 0.000044, Train R2: 0.7088, Test R2: 0.6639\n",
      "Epoch: 2700, Train Loss: 0.000043, Train R2: 0.7090, Test R2: 0.6639\n",
      "Epoch: 2800, Train Loss: 0.000043, Train R2: 0.7092, Test R2: 0.6638\n",
      "Epoch: 2900, Train Loss: 0.000044, Train R2: 0.7080, Test R2: 0.6663\n",
      "Epoch: 3000, Train Loss: 0.000043, Train R2: 0.7095, Test R2: 0.6636\n",
      "Epoch: 3100, Train Loss: 0.000043, Train R2: 0.7097, Test R2: 0.6636\n",
      "Epoch: 3200, Train Loss: 0.000043, Train R2: 0.7090, Test R2: 0.6657\n",
      "Epoch: 3300, Train Loss: 0.000043, Train R2: 0.7100, Test R2: 0.6633\n",
      "Epoch: 3400, Train Loss: 0.000043, Train R2: 0.7101, Test R2: 0.6633\n",
      "Epoch: 3500, Train Loss: 0.000044, Train R2: 0.7074, Test R2: 0.6553\n",
      "Epoch: 3600, Train Loss: 0.000043, Train R2: 0.7103, Test R2: 0.6631\n",
      "Epoch: 3700, Train Loss: 0.000043, Train R2: 0.7105, Test R2: 0.6630\n",
      "Epoch: 3800, Train Loss: 0.000043, Train R2: 0.7106, Test R2: 0.6630\n",
      "Epoch: 3900, Train Loss: 0.000043, Train R2: 0.7106, Test R2: 0.6636\n",
      "Epoch: 4000, Train Loss: 0.000043, Train R2: 0.7108, Test R2: 0.6628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4100, Train Loss: 0.000043, Train R2: 0.7109, Test R2: 0.6627\n",
      "Epoch: 4200, Train Loss: 0.000043, Train R2: 0.7098, Test R2: 0.6581\n",
      "Epoch: 4300, Train Loss: 0.000043, Train R2: 0.7110, Test R2: 0.6626\n",
      "Epoch: 4400, Train Loss: 0.000043, Train R2: 0.7111, Test R2: 0.6626\n",
      "Epoch: 4500, Train Loss: 0.000045, Train R2: 0.6998, Test R2: 0.6417\n",
      "Epoch: 4600, Train Loss: 0.000043, Train R2: 0.7112, Test R2: 0.6624\n",
      "Epoch: 4700, Train Loss: 0.000043, Train R2: 0.7113, Test R2: 0.6624\n",
      "Epoch: 4800, Train Loss: 0.000045, Train R2: 0.7006, Test R2: 0.6424\n",
      "Epoch: 4900, Train Loss: 0.000043, Train R2: 0.7114, Test R2: 0.6623\n",
      "Epoch: 5000, Train Loss: 0.000043, Train R2: 0.7115, Test R2: 0.6623\n",
      "Epoch: 5100, Train Loss: 0.000044, Train R2: 0.7053, Test R2: 0.6486\n",
      "Epoch: 5200, Train Loss: 0.000043, Train R2: 0.7116, Test R2: 0.6623\n",
      "Epoch: 5300, Train Loss: 0.000043, Train R2: 0.7117, Test R2: 0.6622\n",
      "Epoch: 5400, Train Loss: 0.000044, Train R2: 0.7083, Test R2: 0.6651\n",
      "Epoch: 5500, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6622\n",
      "Epoch: 5600, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6621\n",
      "Epoch: 5700, Train Loss: 0.000043, Train R2: 0.7118, Test R2: 0.6621\n",
      "Epoch: 5800, Train Loss: 0.000043, Train R2: 0.7119, Test R2: 0.6620\n",
      "Epoch: 5900, Train Loss: 0.000043, Train R2: 0.7119, Test R2: 0.6620\n",
      "Epoch: 6000, Train Loss: 0.000043, Train R2: 0.7120, Test R2: 0.6620\n",
      "Epoch: 6100, Train Loss: 0.000044, Train R2: 0.7089, Test R2: 0.6649\n",
      "Epoch: 6200, Train Loss: 0.000043, Train R2: 0.7120, Test R2: 0.6619\n",
      "Epoch: 6300, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6619\n",
      "Epoch: 6400, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6619\n",
      "Epoch: 6500, Train Loss: 0.000043, Train R2: 0.7121, Test R2: 0.6612\n",
      "Epoch: 6600, Train Loss: 0.000043, Train R2: 0.7122, Test R2: 0.6618\n",
      "Epoch: 6700, Train Loss: 0.000043, Train R2: 0.7122, Test R2: 0.6618\n",
      "Epoch: 6800, Train Loss: 0.000043, Train R2: 0.7107, Test R2: 0.6644\n",
      "Epoch: 6900, Train Loss: 0.000043, Train R2: 0.7122, Test R2: 0.6618\n",
      "Epoch: 7000, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6617\n",
      "Epoch: 7100, Train Loss: 0.000043, Train R2: 0.7116, Test R2: 0.6585\n",
      "Epoch: 7200, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6619\n",
      "Epoch: 7300, Train Loss: 0.000043, Train R2: 0.7123, Test R2: 0.6617\n",
      "Epoch: 7400, Train Loss: 0.000043, Train R2: 0.7124, Test R2: 0.6617\n",
      "Epoch: 7500, Train Loss: 0.000043, Train R2: 0.7111, Test R2: 0.6642\n",
      "Epoch: 7600, Train Loss: 0.000043, Train R2: 0.7124, Test R2: 0.6616\n",
      "Epoch: 7700, Train Loss: 0.000043, Train R2: 0.7124, Test R2: 0.6616\n",
      "Epoch: 7800, Train Loss: 0.000053, Train R2: 0.6431, Test R2: 0.6276\n",
      "Epoch: 7900, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6614\n",
      "Epoch: 8000, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6616\n",
      "Epoch: 8100, Train Loss: 0.000044, Train R2: 0.7080, Test R2: 0.6508\n",
      "Epoch: 8200, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6613\n",
      "Epoch: 8300, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6615\n",
      "Epoch: 8400, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6613\n",
      "Epoch: 8500, Train Loss: 0.000043, Train R2: 0.7125, Test R2: 0.6611\n",
      "Epoch: 8600, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6615\n",
      "Epoch: 8700, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6620\n",
      "Epoch: 8800, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6612\n",
      "Epoch: 8900, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6614\n",
      "Epoch: 9000, Train Loss: 0.000043, Train R2: 0.7126, Test R2: 0.6614\n",
      "Epoch: 9100, Train Loss: 0.000043, Train R2: 0.7120, Test R2: 0.6582\n",
      "Epoch: 9200, Train Loss: 0.000043, Train R2: 0.7127, Test R2: 0.6614\n",
      "Epoch: 9300, Train Loss: 0.000043, Train R2: 0.7127, Test R2: 0.6614\n",
      "Epoch: 9400, Train Loss: 0.000047, Train R2: 0.6833, Test R2: 0.6530\n",
      "Epoch: 9500, Train Loss: 0.000043, Train R2: 0.7127, Test R2: 0.6614\n",
      "Epoch: 9600, Train Loss: 0.000043, Train R2: 0.7127, Test R2: 0.6613\n",
      "Epoch: 9700, Train Loss: 0.000047, Train R2: 0.6837, Test R2: 0.6531\n",
      "Epoch: 9800, Train Loss: 0.000043, Train R2: 0.7127, Test R2: 0.6613\n",
      "Epoch: 9900, Train Loss: 0.000043, Train R2: 0.7127, Test R2: 0.6613\n",
      "Epoch: 100, Train Loss: 0.000131, Train R2: 0.1218, Test R2: -0.0389\n",
      "Epoch: 200, Train Loss: 0.000101, Train R2: 0.3243, Test R2: 0.1743\n",
      "Epoch: 300, Train Loss: 0.000084, Train R2: 0.4371, Test R2: 0.3078\n",
      "Epoch: 400, Train Loss: 0.000072, Train R2: 0.5197, Test R2: 0.4186\n",
      "Epoch: 500, Train Loss: 0.000063, Train R2: 0.5794, Test R2: 0.5034\n",
      "Epoch: 600, Train Loss: 0.000057, Train R2: 0.6201, Test R2: 0.5635\n",
      "Epoch: 700, Train Loss: 0.000053, Train R2: 0.6470, Test R2: 0.6042\n",
      "Epoch: 800, Train Loss: 0.000050, Train R2: 0.6644, Test R2: 0.6312\n",
      "Epoch: 900, Train Loss: 0.000048, Train R2: 0.6759, Test R2: 0.6489\n",
      "Epoch: 1000, Train Loss: 0.000047, Train R2: 0.6837, Test R2: 0.6607\n",
      "Epoch: 1100, Train Loss: 0.000046, Train R2: 0.6895, Test R2: 0.6688\n",
      "Epoch: 1200, Train Loss: 0.000046, Train R2: 0.6942, Test R2: 0.6746\n",
      "Epoch: 1300, Train Loss: 0.000045, Train R2: 0.6982, Test R2: 0.6790\n",
      "Epoch: 1400, Train Loss: 0.000045, Train R2: 0.7017, Test R2: 0.6825\n",
      "Epoch: 1500, Train Loss: 0.000044, Train R2: 0.7050, Test R2: 0.6853\n",
      "Epoch: 1600, Train Loss: 0.000044, Train R2: 0.7081, Test R2: 0.6877\n",
      "Epoch: 1700, Train Loss: 0.000043, Train R2: 0.7109, Test R2: 0.6897\n",
      "Epoch: 1800, Train Loss: 0.000043, Train R2: 0.7136, Test R2: 0.6914\n",
      "Epoch: 1900, Train Loss: 0.000042, Train R2: 0.7160, Test R2: 0.6928\n",
      "Epoch: 2000, Train Loss: 0.000042, Train R2: 0.7183, Test R2: 0.6940\n",
      "Epoch: 2100, Train Loss: 0.000042, Train R2: 0.7203, Test R2: 0.6951\n",
      "Epoch: 2200, Train Loss: 0.000042, Train R2: 0.7222, Test R2: 0.6960\n",
      "Epoch: 2300, Train Loss: 0.000041, Train R2: 0.7239, Test R2: 0.6968\n",
      "Epoch: 2400, Train Loss: 0.000041, Train R2: 0.7254, Test R2: 0.6974\n",
      "Epoch: 2500, Train Loss: 0.000041, Train R2: 0.7267, Test R2: 0.6980\n",
      "Epoch: 2600, Train Loss: 0.000041, Train R2: 0.7280, Test R2: 0.6984\n",
      "Epoch: 2700, Train Loss: 0.000040, Train R2: 0.7290, Test R2: 0.6987\n",
      "Epoch: 2800, Train Loss: 0.000040, Train R2: 0.7300, Test R2: 0.6990\n",
      "Epoch: 2900, Train Loss: 0.000040, Train R2: 0.7309, Test R2: 0.6992\n",
      "Epoch: 3000, Train Loss: 0.000040, Train R2: 0.7316, Test R2: 0.6993\n",
      "Epoch: 3100, Train Loss: 0.000040, Train R2: 0.7323, Test R2: 0.6993\n",
      "Epoch: 3200, Train Loss: 0.000040, Train R2: 0.7329, Test R2: 0.6993\n",
      "Epoch: 3300, Train Loss: 0.000040, Train R2: 0.7334, Test R2: 0.6993\n",
      "Epoch: 3400, Train Loss: 0.000040, Train R2: 0.7339, Test R2: 0.6992\n",
      "Epoch: 3500, Train Loss: 0.000040, Train R2: 0.7343, Test R2: 0.6990\n",
      "Epoch: 3600, Train Loss: 0.000040, Train R2: 0.7346, Test R2: 0.6988\n",
      "Epoch: 3700, Train Loss: 0.000040, Train R2: 0.7350, Test R2: 0.6986\n",
      "Epoch: 3800, Train Loss: 0.000040, Train R2: 0.7352, Test R2: 0.6984\n",
      "Epoch: 3900, Train Loss: 0.000040, Train R2: 0.7355, Test R2: 0.6982\n",
      "Epoch: 4000, Train Loss: 0.000039, Train R2: 0.7357, Test R2: 0.6979\n",
      "Epoch: 4100, Train Loss: 0.000039, Train R2: 0.7359, Test R2: 0.6976\n",
      "Epoch: 4200, Train Loss: 0.000039, Train R2: 0.7361, Test R2: 0.6973\n",
      "Epoch: 4300, Train Loss: 0.000039, Train R2: 0.7363, Test R2: 0.6970\n",
      "Epoch: 4400, Train Loss: 0.000039, Train R2: 0.7364, Test R2: 0.6967\n",
      "Epoch: 4500, Train Loss: 0.000039, Train R2: 0.7365, Test R2: 0.6963\n",
      "Epoch: 4600, Train Loss: 0.000039, Train R2: 0.7367, Test R2: 0.6960\n",
      "Epoch: 4700, Train Loss: 0.000039, Train R2: 0.7368, Test R2: 0.6956\n",
      "Epoch: 4800, Train Loss: 0.000039, Train R2: 0.7369, Test R2: 0.6953\n",
      "Epoch: 4900, Train Loss: 0.000039, Train R2: 0.7370, Test R2: 0.6949\n",
      "Epoch: 5000, Train Loss: 0.000039, Train R2: 0.7371, Test R2: 0.6945\n",
      "Epoch: 5100, Train Loss: 0.000039, Train R2: 0.7372, Test R2: 0.6942\n",
      "Epoch: 5200, Train Loss: 0.000039, Train R2: 0.7373, Test R2: 0.6938\n",
      "Epoch: 5300, Train Loss: 0.000039, Train R2: 0.7374, Test R2: 0.6934\n",
      "Epoch: 5400, Train Loss: 0.000039, Train R2: 0.7375, Test R2: 0.6931\n",
      "Epoch: 5500, Train Loss: 0.000039, Train R2: 0.7371, Test R2: 0.6941\n",
      "Epoch: 5600, Train Loss: 0.000039, Train R2: 0.7377, Test R2: 0.6924\n",
      "Epoch: 5700, Train Loss: 0.000039, Train R2: 0.7377, Test R2: 0.6920\n",
      "Epoch: 5800, Train Loss: 0.000039, Train R2: 0.7378, Test R2: 0.6921\n",
      "Epoch: 5900, Train Loss: 0.000039, Train R2: 0.7378, Test R2: 0.6914\n",
      "Epoch: 6000, Train Loss: 0.000039, Train R2: 0.7379, Test R2: 0.6911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6100, Train Loss: 0.000039, Train R2: 0.7376, Test R2: 0.6921\n",
      "Epoch: 6200, Train Loss: 0.000039, Train R2: 0.7380, Test R2: 0.6906\n",
      "Epoch: 6300, Train Loss: 0.000039, Train R2: 0.7380, Test R2: 0.6903\n",
      "Epoch: 6400, Train Loss: 0.000039, Train R2: 0.7380, Test R2: 0.6895\n",
      "Epoch: 6500, Train Loss: 0.000039, Train R2: 0.7381, Test R2: 0.6898\n",
      "Epoch: 6600, Train Loss: 0.000039, Train R2: 0.7381, Test R2: 0.6896\n",
      "Epoch: 6700, Train Loss: 0.000039, Train R2: 0.7382, Test R2: 0.6894\n",
      "Epoch: 6800, Train Loss: 0.000039, Train R2: 0.7382, Test R2: 0.6892\n",
      "Epoch: 6900, Train Loss: 0.000039, Train R2: 0.7382, Test R2: 0.6886\n",
      "Epoch: 7000, Train Loss: 0.000039, Train R2: 0.7382, Test R2: 0.6887\n",
      "Epoch: 7100, Train Loss: 0.000039, Train R2: 0.7383, Test R2: 0.6886\n",
      "Epoch: 7200, Train Loss: 0.000039, Train R2: 0.7383, Test R2: 0.6884\n",
      "Epoch: 7300, Train Loss: 0.000039, Train R2: 0.7383, Test R2: 0.6884\n",
      "Epoch: 7400, Train Loss: 0.000039, Train R2: 0.7383, Test R2: 0.6880\n",
      "Epoch: 7500, Train Loss: 0.000039, Train R2: 0.7383, Test R2: 0.6879\n",
      "Epoch: 7600, Train Loss: 0.000039, Train R2: 0.7371, Test R2: 0.6896\n",
      "Epoch: 7700, Train Loss: 0.000039, Train R2: 0.7383, Test R2: 0.6875\n",
      "Epoch: 7800, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6874\n",
      "Epoch: 7900, Train Loss: 0.000039, Train R2: 0.7364, Test R2: 0.6818\n",
      "Epoch: 8000, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6871\n",
      "Epoch: 8100, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6870\n",
      "Epoch: 8200, Train Loss: 0.000044, Train R2: 0.7070, Test R2: 0.6441\n",
      "Epoch: 8300, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6867\n",
      "Epoch: 8400, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6867\n",
      "Epoch: 8500, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6864\n",
      "Epoch: 8600, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6865\n",
      "Epoch: 8700, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6864\n",
      "Epoch: 8800, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6860\n",
      "Epoch: 8900, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6865\n",
      "Epoch: 9000, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6861\n",
      "Epoch: 9100, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6861\n",
      "Epoch: 9200, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6856\n",
      "Epoch: 9300, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6858\n",
      "Epoch: 9400, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6858\n",
      "Epoch: 9500, Train Loss: 0.000039, Train R2: 0.7382, Test R2: 0.6868\n",
      "Epoch: 9600, Train Loss: 0.000039, Train R2: 0.7385, Test R2: 0.6856\n",
      "Epoch: 9700, Train Loss: 0.000039, Train R2: 0.7385, Test R2: 0.6856\n",
      "Epoch: 9800, Train Loss: 0.000039, Train R2: 0.7384, Test R2: 0.6847\n",
      "Epoch: 9900, Train Loss: 0.000039, Train R2: 0.7385, Test R2: 0.6854\n"
     ]
    }
   ],
   "source": [
    "# model set up\n",
    "for key_ in A_dic.keys():\n",
    "    # list\n",
    "    r2_train_list = []\n",
    "    r2_test_list = []\n",
    "    # device\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "    # data\n",
    "    data = A_data_dic[key_]\n",
    "    data = data.to(device)\n",
    "    model = GCN().to(device)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-9)\n",
    "\n",
    "    # Training the model \n",
    "    epochs = 10000\n",
    "    for epoch in range(1, epochs):\n",
    "        loss = train()\n",
    "        train_mse, test_mse, train_r2, test_r2 = test()\n",
    "        if epoch%100 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {train_mse:.6f}, Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}')\n",
    "            # \n",
    "            r2_train_list.append(float(train_r2.cpu().numpy()))\n",
    "            r2_test_list.append(float(test_r2.cpu().numpy()))\n",
    "    \n",
    "    # Save the best testing r2 and corresponding training r2\n",
    "    gcn_performance_one_layer_df.loc['testing', key_] = np.max(r2_test_list)\n",
    "    idx = r2_test_list.index(np.max(r2_test_list))\n",
    "    gcn_performance_one_layer_df.loc['training', key_] = r2_train_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dee26407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spatial</th>\n",
       "      <th>aggregate</th>\n",
       "      <th>strong</th>\n",
       "      <th>weak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>0.734623</td>\n",
       "      <td>0.708316</td>\n",
       "      <td>0.708007</td>\n",
       "      <td>0.732303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.685014</td>\n",
       "      <td>0.646084</td>\n",
       "      <td>0.666264</td>\n",
       "      <td>0.699321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           spatial  aggregate    strong      weak\n",
       "training  0.734623   0.708316  0.708007  0.732303\n",
       "testing   0.685014   0.646084  0.666264  0.699321"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_performance_one_layer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b19b15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the performance\n",
    "gcn_performance_dic['homo & one-layer'] = gcn_performance_one_layer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc4931",
   "metadata": {},
   "source": [
    "# GCN (Hetero & Depth = 2)\n",
    "\n",
    "Four scenarios\n",
    "- Three spatial networks\n",
    "- Three strong networks\n",
    "- Three weak networks\n",
    "- One spatial network + two weak networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb926b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8d3d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the baseline regressions\n",
    "input_vars = ['pop_total_2016',\n",
    "              'pop_density_2016',\n",
    "              'age_median_2016', \n",
    "              'household_size_avg_2016',\n",
    "              'sex_male_ratio_2016', \n",
    "              'race_white_ratio_2016',\n",
    "              'edu_bachelor_ratio_2016',\n",
    "              'edu_master_ratio_2016',\n",
    "              'edu_master_ratio_2016', \n",
    "              'vehicle_per_capita_2016']\n",
    "\n",
    "# predict inc_per_capita_2018\n",
    "output_var = 'inc_per_capita_2018'\n",
    "\n",
    "X = normalize(df_socioecon_shp[input_vars].values, axis = 0)\n",
    "y = normalize(df_socioecon_shp[output_var].values.reshape(-1, 1), axis = 0).reshape(-1, 1)\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebc711f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(682)\n",
      "tensor(310)\n"
     ]
    }
   ],
   "source": [
    "# creating the train and test masks\n",
    "np.random.seed(seed = 42)\n",
    "train_mask = np.random.choice([True, False], X_tensor.size()[0], p = [0.67,0.33]) #.reshape(-1, 1)\n",
    "test_mask = ~train_mask\n",
    "train_mask_tensor = torch.from_numpy(train_mask)\n",
    "test_mask_tensor = torch.from_numpy(test_mask)\n",
    "\n",
    "print(train_mask_tensor.sum())\n",
    "print(test_mask_tensor.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a3fde5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adjacency dictionary.\n",
    "A_dic = {}\n",
    "A_dic['spatial (3)'] = {}\n",
    "A_dic['strong (3)'] = {}\n",
    "A_dic['weak (3)'] = {}\n",
    "A_dic['spatial & weak (1 + 2)'] = {}\n",
    "A_dic['spatial & strong & weak (1 + 1 + 1)'] = {}\n",
    "\n",
    "# specify the heterogeneous spatial networks\n",
    "A_dic['spatial (3)']['queen'] = utils.turn_df_to_adj(spatial_network_dic['boston_queen_contiguity_adj_df'], df_shp)\n",
    "A_dic['spatial (3)']['queen'] = A_dic['spatial (3)']['queen'].values\n",
    "A_dic['spatial (3)']['rook'] = utils.turn_df_to_adj(spatial_network_dic['boston_rook_contiguity_adj_df'], df_shp)\n",
    "A_dic['spatial (3)']['rook'] = A_dic['spatial (3)']['rook'].values\n",
    "A_dic['spatial (3)']['5nn'] = utils.turn_df_to_adj(spatial_network_dic['boston_5nn_contiguity_adj_df'], df_shp)\n",
    "A_dic['spatial (3)']['5nn'] = A_dic['spatial (3)']['5nn'].values\n",
    "\n",
    "# specify the heterogeneous strong mobility networks\n",
    "A_dic['strong (3)']['Office'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['Office'], df_shp)\n",
    "A_dic['strong (3)']['Office'] = A_dic['strong (3)']['Office'].values\n",
    "A_dic['strong (3)']['Residential'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['Residential'], df_shp)\n",
    "A_dic['strong (3)']['Residential'] = A_dic['strong (3)']['Residential'].values\n",
    "A_dic['strong (3)']['Building'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['Building'], df_shp)\n",
    "A_dic['strong (3)']['Building'] = A_dic['strong (3)']['Building'].values\n",
    "\n",
    "# specify the heterogeneous weak mobility networks\n",
    "A_dic['weak (3)']['New American'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['New American'], df_shp)\n",
    "A_dic['weak (3)']['New American'] = A_dic['weak (3)']['New American'].values\n",
    "A_dic['weak (3)']['French'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['French'], df_shp)\n",
    "A_dic['weak (3)']['French'] = A_dic['weak (3)']['French'].values\n",
    "A_dic['weak (3)']['Salad'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['Salad'], df_shp)\n",
    "A_dic['weak (3)']['Salad'] = A_dic['weak (3)']['Salad'].values\n",
    "\n",
    "# specify the heterogeneous spatial + weak mobility networks\n",
    "A_dic['spatial & weak (1 + 2)']['New American'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['New American'], df_shp)\n",
    "A_dic['spatial & weak (1 + 2)']['New American'] = A_dic['spatial & weak (1 + 2)']['New American'].values\n",
    "A_dic['spatial & weak (1 + 2)']['French'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['French'], df_shp)\n",
    "A_dic['spatial & weak (1 + 2)']['French'] = A_dic['spatial & weak (1 + 2)']['French'].values\n",
    "A_dic['spatial & weak (1 + 2)']['queen'] = utils.turn_df_to_adj(spatial_network_dic['boston_queen_contiguity_adj_df'], df_shp)\n",
    "A_dic['spatial & weak (1 + 2)']['queen'] = A_dic['spatial & weak (1 + 2)']['queen'].values\n",
    "\n",
    "# specify the heterogeneous spatial + strong + weak mobility networks\n",
    "A_dic['spatial & strong & weak (1 + 1 + 1)']['New American'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['New American'], df_shp)\n",
    "A_dic['spatial & strong & weak (1 + 1 + 1)']['New American'] = A_dic['spatial & strong & weak (1 + 1 + 1)']['New American'].values\n",
    "A_dic['spatial & strong & weak (1 + 1 + 1)']['Office'] = utils.turn_df_to_adj(A_home_activity_unweighted_dic[1.0]['Office'], df_shp)\n",
    "A_dic['spatial & strong & weak (1 + 1 + 1)']['Office'] = A_dic['spatial & strong & weak (1 + 1 + 1)']['Office'].values\n",
    "A_dic['spatial & strong & weak (1 + 1 + 1)']['queen'] = utils.turn_df_to_adj(spatial_network_dic['boston_queen_contiguity_adj_df'], df_shp)\n",
    "A_dic['spatial & strong & weak (1 + 1 + 1)']['queen'] = A_dic['spatial & strong & weak (1 + 1 + 1)']['queen'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7047cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN_1layer(torch.nn.Module):\n",
    "    # damn it. The script sucks. I will rewrite it to freely specify the # of layers. \n",
    "    def __init__(self, metadata):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({edge_type: GCNConv(-1, 1, bias = True) for edge_type in metadata[1]})        \n",
    "        self.lin1 = Linear(-1, 1) # 15 is the hidden channels. Feel free to change it. \n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)['ct'] + self.lin1(x_dict['ct'])\n",
    "#         x_dict = {'ct':x_dict.relu()}\n",
    "#         x_dict = self.conv2(x_dict, edge_index_dict)['ct'] + self.lin2(x_dict['ct'])\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "148a072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN_2layer(torch.nn.Module):\n",
    "    # damn it. The script sucks. I will rewrite it to freely specify the # of layers. \n",
    "    def __init__(self, metadata):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({edge_type: GCNConv(-1, 15, bias = True) for edge_type in metadata[1]})\n",
    "        self.conv2 = HeteroConv({edge_type: GCNConv(15, 1, bias = True) for edge_type in metadata[1]})\n",
    "        \n",
    "        self.lin1 = Linear(-1, 15) # 15 is the hidden channels. Feel free to change it. \n",
    "        self.lin2 = Linear(15, 1)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)['ct'] + self.lin1(x_dict['ct'])\n",
    "        x_dict = {'ct':x_dict.relu()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)['ct'] + self.lin2(x_dict['ct'])\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ef3ed0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN_3layer(torch.nn.Module):\n",
    "    # damn it. The script sucks. I will rewrite it to freely specify the # of layers. \n",
    "    def __init__(self, metadata):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({edge_type: GCNConv(-1, 15, bias = True) for edge_type in metadata[1]})\n",
    "        self.conv2 = HeteroConv({edge_type: GCNConv(15, 15, bias = True) for edge_type in metadata[1]})\n",
    "        self.conv3 = HeteroConv({edge_type: GCNConv(15, 1, bias = True) for edge_type in metadata[1]})\n",
    "        \n",
    "        self.lin1 = Linear(-1, 15) # 15 is the hidden channels. Feel free to change it. \n",
    "        self.lin2 = Linear(15, 15)\n",
    "        self.lin3 = Linear(15, 1)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)['ct'] + self.lin1(x_dict['ct'])\n",
    "        x_dict = {'ct':x_dict.relu()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)['ct'] + self.lin2(x_dict['ct'])\n",
    "        x_dict = {'ct':x_dict.relu()}\n",
    "        x_dict = self.conv3(x_dict, edge_index_dict)['ct'] + self.lin3(x_dict['ct'])\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6445d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN_4layer(torch.nn.Module):\n",
    "    # damn it. The script sucks. I will rewrite it to freely specify the # of layers. \n",
    "    def __init__(self, metadata):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({edge_type: GCNConv(-1, 15, bias = True) for edge_type in metadata[1]})\n",
    "        self.conv2 = HeteroConv({edge_type: GCNConv(15, 15, bias = True) for edge_type in metadata[1]})\n",
    "        self.conv3 = HeteroConv({edge_type: GCNConv(15, 15, bias = True) for edge_type in metadata[1]})\n",
    "        self.conv4 = HeteroConv({edge_type: GCNConv(15, 1, bias = True) for edge_type in metadata[1]})\n",
    "        \n",
    "        self.lin1 = Linear(-1, 15) # 15 is the hidden channels. Feel free to change it. \n",
    "        self.lin2 = Linear(15, 15)\n",
    "        self.lin3 = Linear(15, 15)\n",
    "        self.lin4 = Linear(15, 1)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)['ct'] + self.lin1(x_dict['ct'])\n",
    "        x_dict = {'ct':x_dict.relu()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)['ct'] + self.lin2(x_dict['ct'])\n",
    "        x_dict = {'ct':x_dict.relu()}\n",
    "        x_dict = self.conv3(x_dict, edge_index_dict)['ct'] + self.lin3(x_dict['ct'])\n",
    "        x_dict = {'ct':x_dict.relu()}\n",
    "        x_dict = self.conv4(x_dict, edge_index_dict)['ct'] + self.lin4(x_dict['ct'])\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dea80d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 definition\n",
    "def r2_loss(output, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - output) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "010b7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train fun\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model.forward(data.x_dict, data.edge_index_dict) \n",
    "    mask = data['ct'].train_mask\n",
    "    loss = F.mse_loss(out[mask], data['ct'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "17421e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the test fun\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model.forward(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    train_pred = out[data['ct'].train_mask]\n",
    "    test_pred = out[data['ct'].test_mask]\n",
    "    \n",
    "    train_mse = F.mse_loss(train_pred, data['ct'].y[data['ct'].train_mask])\n",
    "    test_mse = F.mse_loss(test_pred, data['ct'].y[data['ct'].test_mask])\n",
    "    train_r2 = r2_loss(train_pred, data['ct'].y[data['ct'].train_mask])\n",
    "    test_r2 = r2_loss(test_pred, data['ct'].y[data['ct'].test_mask])\n",
    "    return train_mse, test_mse, train_r2, test_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5d5183bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data\n",
    "data = HeteroData()\n",
    "\n",
    "# init nodes\n",
    "data['ct'].x = X_tensor\n",
    "data['ct'].y = y_tensor\n",
    "data['ct'].train_mask = train_mask_tensor\n",
    "data['ct'].test_mask = test_mask_tensor\n",
    "\n",
    "# add the hetero edges\n",
    "for key_ in A_dic['spatial & weak (1 + 2)'].keys():\n",
    "    # create the adj matrix\n",
    "    A = A_dic['spatial & weak (1 + 2)'][key_]\n",
    "\n",
    "#     # remove the self loop\n",
    "#     np.fill_diagonal(A, 0.0)\n",
    "\n",
    "    # create the list of edges\n",
    "    row_idx = csr_matrix(A).tocoo().row\n",
    "    col_idx = csr_matrix(A).tocoo().col\n",
    "    data_idx = csr_matrix(A).tocoo().data\n",
    "\n",
    "    # edge index\n",
    "    edge_index = torch.tensor([list(row_idx)+list(col_idx), list(col_idx)+list(row_idx)], dtype = torch.long)\n",
    "    data['ct', key_, 'ct'].edge_index = edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "95de11cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mct\u001b[0m={\n",
       "    x=[992, 10],\n",
       "    y=[992, 1],\n",
       "    train_mask=[992],\n",
       "    test_mask=[992]\n",
       "  },\n",
       "  \u001b[1m(ct, New American, ct)\u001b[0m={ edge_index=[2, 18316] },\n",
       "  \u001b[1m(ct, French, ct)\u001b[0m={ edge_index=[2, 5012] },\n",
       "  \u001b[1m(ct, queen, ct)\u001b[0m={ edge_index=[2, 11504] }\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dff4f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = HeteroGNN_1layer(data.metadata())\n",
    "# model = HeteroGNN_2layer(data.metadata())\n",
    "# model = HeteroGNN_3layer(data.metadata())\n",
    "# model = HeteroGNN_4layer(data.metadata())\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-9) # need to readjust these parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "59dabc18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Train Loss: 0.000075, Train R2: 0.4999, Test R2: 0.4184\n",
      "Epoch: 1000, Train Loss: 0.000051, Train R2: 0.6574, Test R2: 0.5831\n",
      "Epoch: 1500, Train Loss: 0.000043, Train R2: 0.7106, Test R2: 0.6302\n",
      "Epoch: 2000, Train Loss: 0.000039, Train R2: 0.7394, Test R2: 0.6592\n",
      "Epoch: 2500, Train Loss: 0.000036, Train R2: 0.7562, Test R2: 0.6791\n",
      "Epoch: 3000, Train Loss: 0.000035, Train R2: 0.7659, Test R2: 0.6931\n",
      "Epoch: 3500, Train Loss: 0.000034, Train R2: 0.7713, Test R2: 0.7029\n",
      "Epoch: 4000, Train Loss: 0.000034, Train R2: 0.7742, Test R2: 0.7095\n",
      "Epoch: 4500, Train Loss: 0.000034, Train R2: 0.7700, Test R2: 0.7024\n",
      "Epoch: 5000, Train Loss: 0.000033, Train R2: 0.7765, Test R2: 0.7152\n",
      "Epoch: 5500, Train Loss: 0.000033, Train R2: 0.7767, Test R2: 0.7172\n",
      "Epoch: 6000, Train Loss: 0.000033, Train R2: 0.7772, Test R2: 0.7165\n",
      "Epoch: 6500, Train Loss: 0.000033, Train R2: 0.7771, Test R2: 0.7176\n",
      "Epoch: 7000, Train Loss: 0.000033, Train R2: 0.7775, Test R2: 0.7165\n",
      "Epoch: 7500, Train Loss: 0.000033, Train R2: 0.7776, Test R2: 0.7164\n",
      "Epoch: 8000, Train Loss: 0.000034, Train R2: 0.7706, Test R2: 0.7036\n",
      "Epoch: 8500, Train Loss: 0.000033, Train R2: 0.7776, Test R2: 0.7160\n",
      "Epoch: 9000, Train Loss: 0.000033, Train R2: 0.7774, Test R2: 0.7145\n",
      "Epoch: 9500, Train Loss: 0.000033, Train R2: 0.7777, Test R2: 0.7157\n",
      "Epoch: 10000, Train Loss: 0.000033, Train R2: 0.7776, Test R2: 0.7161\n",
      "Epoch: 10500, Train Loss: 0.000033, Train R2: 0.7777, Test R2: 0.7154\n",
      "Epoch: 11000, Train Loss: 0.000033, Train R2: 0.7777, Test R2: 0.7154\n",
      "Epoch: 11500, Train Loss: 0.000063, Train R2: 0.5816, Test R2: 0.5774\n",
      "Epoch: 12000, Train Loss: 0.000033, Train R2: 0.7777, Test R2: 0.7151\n",
      "Epoch: 12500, Train Loss: 0.000033, Train R2: 0.7777, Test R2: 0.7154\n",
      "Epoch: 13000, Train Loss: 0.000065, Train R2: 0.5621, Test R2: 0.4899\n",
      "Epoch: 13500, Train Loss: 0.000033, Train R2: 0.7777, Test R2: 0.7149\n",
      "Epoch: 14000, Train Loss: 0.000035, Train R2: 0.7665, Test R2: 0.6967\n",
      "Epoch: 14500, Train Loss: 0.000033, Train R2: 0.7777, Test R2: 0.7147\n",
      "Epoch: 15000, Train Loss: 0.000037, Train R2: 0.7538, Test R2: 0.7057\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "epochs = 15001\n",
    "for epoch in range(1, epochs):\n",
    "    loss = train()\n",
    "    if epoch%500 == 0:\n",
    "        train_mse, test_mse, train_r2, test_r2 = test()\n",
    "        print(f'Epoch: {epoch:03d}, Train Loss: {train_mse:.6f}, Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4bf67c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_performance_two_layer_df = pd.DataFrame(np.zeros((2, 5)), \n",
    "                                           index = ['training', 'testing'],\n",
    "                                           columns = list(A_dic.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "08d4e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "gcn_performance_two_layer_df.loc[['training', 'testing'], 'spatial (3)'] = 0.818, 0.735\n",
    "gcn_performance_two_layer_df.loc[['training', 'testing'], 'strong (3)'] = 0.855, 0.688\n",
    "gcn_performance_two_layer_df.loc[['training', 'testing'], 'weak (3)'] = 0.893, 0.751\n",
    "gcn_performance_two_layer_df.loc[['training', 'testing'], 'spatial & weak (1 + 2)'] = 0.876, 0.770\n",
    "gcn_performance_two_layer_df.loc[['training', 'testing'], 'spatial & strong & weak (1 + 1 + 1)'] = 0.811, 0.732\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2e15ad80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spatial (3)</th>\n",
       "      <th>strong (3)</th>\n",
       "      <th>weak (3)</th>\n",
       "      <th>spatial &amp; weak (1 + 2)</th>\n",
       "      <th>spatial &amp; strong &amp; weak (1 + 1 + 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.735</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          spatial (3)  strong (3)  weak (3)  spatial & weak (1 + 2)  \\\n",
       "training        0.818       0.855     0.893                   0.876   \n",
       "testing         0.735       0.688     0.751                   0.770   \n",
       "\n",
       "          spatial & strong & weak (1 + 1 + 1)  \n",
       "training                                0.811  \n",
       "testing                                 0.732  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_performance_two_layer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc5ed2",
   "metadata": {},
   "source": [
    "Depth:\n",
    "one layer: 0.777, 0.716\n",
    "two layer: 0.876, 0.770\n",
    "three layer: 0.870, 0.544\n",
    "four layer: 0.907, 0.720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523b6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6286ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeceafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85ffb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f623b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35587864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208fa9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b876b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d4070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b2eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2eb72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64682407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499623df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb804a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a52b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
