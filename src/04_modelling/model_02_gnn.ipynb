{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use GNN to predict econ outputs\n",
    "\n",
    "- Replicating regression benchmarks with GNN.\n",
    "- BOOST the performance. (Only started with simple GNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# GNN packages\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "with open(\"../../data/03_processed/place_graph_X.pickle\", 'rb') as f:\n",
    "    X_place = pickle.load(f) # data frame\n",
    "\n",
    "with open(\"../../data/03_processed/place_graph_A.pickle\", 'rb') as f:\n",
    "    A_place = pickle.load(f) # sparse matrix\n",
    "\n",
    "with open(\"../../data/03_processed/place_graph_weighted_A.pickle\", 'rb') as f:\n",
    "    A_weighted_place = pickle.load(f) # sparse matrix    \n",
    "    \n",
    "with open(\"../../data/03_processed/place_graph_Y.pickle\", 'rb') as f:\n",
    "    Y_place = pickle.load(f) # data frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_per_capita</th>\n",
       "      <th>property_value_median</th>\n",
       "      <th>pop_total</th>\n",
       "      <th>households</th>\n",
       "      <th>race_white_ratio</th>\n",
       "      <th>race_black_ratio</th>\n",
       "      <th>age_median</th>\n",
       "      <th>travel_driving_ratio</th>\n",
       "      <th>edu_bachelor_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_bg_fips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250092011001</th>\n",
       "      <td>46400.0</td>\n",
       "      <td>521300.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.239669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021011</th>\n",
       "      <td>54513.0</td>\n",
       "      <td>464100.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.334669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021012</th>\n",
       "      <td>48486.0</td>\n",
       "      <td>461900.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.967181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.9</td>\n",
       "      <td>0.836538</td>\n",
       "      <td>0.413408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021013</th>\n",
       "      <td>43408.0</td>\n",
       "      <td>391000.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.822360</td>\n",
       "      <td>0.045963</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.761261</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021021</th>\n",
       "      <td>35731.0</td>\n",
       "      <td>403800.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.957663</td>\n",
       "      <td>0.029636</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.902357</td>\n",
       "      <td>0.204301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870001</th>\n",
       "      <td>25345.0</td>\n",
       "      <td>218500.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.926868</td>\n",
       "      <td>0.100338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870002</th>\n",
       "      <td>24643.0</td>\n",
       "      <td>158700.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.984491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.869505</td>\n",
       "      <td>0.127907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870003</th>\n",
       "      <td>28067.0</td>\n",
       "      <td>169300.0</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.896261</td>\n",
       "      <td>0.098936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870004</th>\n",
       "      <td>20110.0</td>\n",
       "      <td>93200.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170880003</th>\n",
       "      <td>30849.0</td>\n",
       "      <td>181100.0</td>\n",
       "      <td>2366.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.989856</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.886241</td>\n",
       "      <td>0.144919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3102 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              inc_per_capita  property_value_median  pop_total  households  \\\n",
       "full_bg_fips                                                                 \n",
       "250092011001         46400.0               521300.0      544.0       259.0   \n",
       "250092021011         54513.0               464100.0      721.0       248.0   \n",
       "250092021012         48486.0               461900.0      518.0       202.0   \n",
       "250092021013         43408.0               391000.0      805.0       288.0   \n",
       "250092021021         35731.0               403800.0     1181.0       402.0   \n",
       "...                      ...                    ...        ...         ...   \n",
       "330170870001         25345.0               218500.0     1479.0       549.0   \n",
       "330170870002         24643.0               158700.0     1612.0       630.0   \n",
       "330170870003         28067.0               169300.0     1657.0       597.0   \n",
       "330170870004         20110.0                93200.0     1087.0       561.0   \n",
       "330170880003         30849.0               181100.0     2366.0       899.0   \n",
       "\n",
       "              race_white_ratio  race_black_ratio  age_median  \\\n",
       "full_bg_fips                                                   \n",
       "250092011001          1.000000          0.000000        52.8   \n",
       "250092021011          0.970874          0.000000        47.4   \n",
       "250092021012          0.967181          0.000000        39.9   \n",
       "250092021013          0.822360          0.045963        35.4   \n",
       "250092021021          0.957663          0.029636        33.8   \n",
       "...                        ...               ...         ...   \n",
       "330170870001          1.000000          0.000000        33.2   \n",
       "330170870002          0.984491          0.000000        38.5   \n",
       "330170870003          1.000000          0.000000        35.9   \n",
       "330170870004          1.000000          0.000000        54.6   \n",
       "330170880003          0.989856          0.005072        42.7   \n",
       "\n",
       "              travel_driving_ratio  edu_bachelor_ratio  \n",
       "full_bg_fips                                            \n",
       "250092011001              0.728395            0.239669  \n",
       "250092021011              0.737931            0.334669  \n",
       "250092021012              0.836538            0.413408  \n",
       "250092021013              0.761261            0.250000  \n",
       "250092021021              0.902357            0.204301  \n",
       "...                            ...                 ...  \n",
       "330170870001              0.926868            0.100338  \n",
       "330170870002              0.869505            0.127907  \n",
       "330170870003              0.896261            0.098936  \n",
       "330170870004              1.000000            0.179310  \n",
       "330170880003              0.886241            0.144919  \n",
       "\n",
       "[3102 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3102x3102 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5290846 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_per_capita_annual_growth</th>\n",
       "      <th>pop_total_annual_growth</th>\n",
       "      <th>property_value_median_annual_growth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_bg_fips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250092011001</th>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021011</th>\n",
       "      <td>0.101</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021012</th>\n",
       "      <td>0.078</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021013</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250092021021</th>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870001</th>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870002</th>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870003</th>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170870004</th>\n",
       "      <td>0.084</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330170880003</th>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              inc_per_capita_annual_growth  pop_total_annual_growth  \\\n",
       "full_bg_fips                                                          \n",
       "250092011001                         0.105                   -0.094   \n",
       "250092021011                         0.101                    0.001   \n",
       "250092021012                         0.078                    0.013   \n",
       "250092021013                         0.005                    0.034   \n",
       "250092021021                         0.125                   -0.037   \n",
       "...                                    ...                      ...   \n",
       "330170870001                         0.094                   -0.031   \n",
       "330170870002                        -0.018                    0.037   \n",
       "330170870003                         0.161                   -0.094   \n",
       "330170870004                         0.084                    0.084   \n",
       "330170880003                         0.049                   -0.044   \n",
       "\n",
       "              property_value_median_annual_growth  \n",
       "full_bg_fips                                       \n",
       "250092011001                                0.062  \n",
       "250092021011                                0.050  \n",
       "250092021012                                0.028  \n",
       "250092021013                                0.027  \n",
       "250092021021                                0.055  \n",
       "...                                           ...  \n",
       "330170870001                                0.020  \n",
       "330170870002                                0.044  \n",
       "330170870003                                0.107  \n",
       "330170870004                                0.030  \n",
       "330170880003                                0.017  \n",
       "\n",
       "[3102 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear reg benchmark (SM Package)\n",
    "\n",
    "- Predicting income. R2 = 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         inc_per_capita   R-squared:                       0.711\n",
      "Model:                            OLS   Adj. R-squared:                  0.710\n",
      "Method:                 Least Squares   F-statistic:                     951.1\n",
      "Date:                Sun, 07 Nov 2021   Prob (F-statistic):               0.00\n",
      "Time:                        21:09:40   Log-Likelihood:                -33359.\n",
      "No. Observations:                3102   AIC:                         6.674e+04\n",
      "Df Residuals:                    3093   BIC:                         6.679e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                 -1.536e+04   1539.515     -9.976      0.000   -1.84e+04   -1.23e+04\n",
      "pop_total                -9.2181      0.614    -15.020      0.000     -10.421      -8.015\n",
      "property_value_median     0.0635      0.001     56.841      0.000       0.061       0.066\n",
      "households               24.2041      1.576     15.363      0.000      21.115      27.293\n",
      "race_white_ratio       9479.7623   1649.305      5.748      0.000    6245.918    1.27e+04\n",
      "race_black_ratio      -2486.9651   1951.549     -1.274      0.203   -6313.428    1339.498\n",
      "age_median              296.8310     31.438      9.442      0.000     235.189     358.473\n",
      "travel_driving_ratio   4363.2212   1203.852      3.624      0.000    2002.792    6723.651\n",
      "edu_bachelor_ratio     3.383e+04   2206.679     15.330      0.000    2.95e+04    3.82e+04\n",
      "==============================================================================\n",
      "Omnibus:                     2055.356   Durbin-Watson:                   1.861\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           148586.687\n",
      "Skew:                           2.397   Prob(JB):                         0.00\n",
      "Kurtosis:                      36.565   Cond. No.                     6.04e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.04e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# predict income with raw data\n",
    "input_vars = ['pop_total', 'property_value_median', \n",
    "              'households', 'race_white_ratio', 'race_black_ratio', 'age_median', \n",
    "              'travel_driving_ratio', 'edu_bachelor_ratio']\n",
    "\n",
    "# specify X and y\n",
    "X = sm.add_constant(X_place[input_vars])\n",
    "output_var = 'inc_per_capita' \n",
    "y = X_place[output_var] # here use X_place\n",
    "\n",
    "# regression on y and X\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.711\n",
      "Model:                            OLS   Adj. R-squared:                  0.710\n",
      "Method:                 Least Squares   F-statistic:                     951.1\n",
      "Date:                Sun, 07 Nov 2021   Prob (F-statistic):               0.00\n",
      "Time:                        21:09:43   Log-Likelihood:                 12452.\n",
      "No. Observations:                3102   AIC:                        -2.489e+04\n",
      "Df Residuals:                    3093   BIC:                        -2.483e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0059      0.001     -9.976      0.000      -0.007      -0.005\n",
      "x1            -0.3036      0.020    -15.020      0.000      -0.343      -0.264\n",
      "x2             0.6438      0.011     56.841      0.000       0.622       0.666\n",
      "x3             0.3038      0.020     15.363      0.000       0.265       0.343\n",
      "x4             0.1612      0.028      5.748      0.000       0.106       0.216\n",
      "x5            -0.0104      0.008     -1.274      0.203      -0.026       0.006\n",
      "x6             0.2582      0.027      9.442      0.000       0.205       0.312\n",
      "x7             0.0711      0.020      3.624      0.000       0.033       0.110\n",
      "x8             0.1978      0.013     15.330      0.000       0.173       0.223\n",
      "==============================================================================\n",
      "Omnibus:                     2055.356   Durbin-Watson:                   1.861\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           148586.687\n",
      "Skew:                           2.397   Prob(JB):                         0.00\n",
      "Kurtosis:                      36.565   Cond. No.                         427.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# predict income with normalized X and y. \n",
    "input_vars = ['pop_total', 'property_value_median', \n",
    "              'households', 'race_white_ratio', 'race_black_ratio', 'age_median', \n",
    "              'travel_driving_ratio', 'edu_bachelor_ratio']\n",
    "\n",
    "# specify X and y\n",
    "X = normalize(X_place[input_vars].values, axis = 0)\n",
    "X = sm.add_constant(X)\n",
    "output_var = 'inc_per_capita'\n",
    "y = normalize(X_place[output_var].values.reshape(-1, 1), axis = 0) # here use X_place\n",
    "\n",
    "# regression on y and X\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating the linear benchmark with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully replicated the sm linear reg by using pytorch. (R2 and parameters are both consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input x and y.\n",
    "input_vars = ['pop_total', 'property_value_median', \n",
    "              'households', 'race_white_ratio', 'race_black_ratio', 'age_median', \n",
    "              'travel_driving_ratio', 'edu_bachelor_ratio']\n",
    "\n",
    "# specify X and y\n",
    "X = normalize(X_place[input_vars].values, axis = 0)\n",
    "\n",
    "output_var = 'inc_per_capita' \n",
    "y = normalize(X_place[output_var].values.reshape(-1, 1), axis = 0).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3102, 8])\n",
      "torch.Size([3102, 1])\n"
     ]
    }
   ],
   "source": [
    "# change types of X and y.\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# tensor\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "\n",
    "print(X_tensor.size())\n",
    "print(y_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up.\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "linear_model = Linear(8, 1, bias = True).to(device)\n",
    "X_tensor = X_tensor.to(device)\n",
    "y_tensor = y_tensor.to(device)\n",
    "# optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(8.1443e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.2233e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.7479e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.7271e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.0750e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.6783e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.4399e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.2924e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.1955e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.1275e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0772e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0390e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0096e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9870e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9695e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9560e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9456e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9375e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9312e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9262e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9223e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9193e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9169e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9151e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9136e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9125e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9116e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9109e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9104e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9100e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9097e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9095e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9093e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9092e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9091e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9091e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9090e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9090e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9090e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9089e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "linear_model.train()\n",
    "\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    out = linear_model(X_tensor)\n",
    "    loss = F.mse_loss(out, y_tensor)\n",
    "    if epoch%100 == 0:\n",
    "        print(loss)\n",
    "    # Here it is. Compute on the WHOLE training set, then evaluate using the mask.\n",
    "    loss.backward()\n",
    "    optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3039,  0.6439,  0.3040,  0.1613, -0.0104,  0.2578,  0.0712,  0.1978]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0059], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# check the weights\n",
    "print(linear_model.weight)\n",
    "print(linear_model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 from sklearn: 0.7109805092148405\n"
     ]
    }
   ],
   "source": [
    "# compute R2\n",
    "# same as above\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = linear_model(X_tensor).cpu().detach().numpy()\n",
    "y_true = y_tensor.cpu().numpy()\n",
    "print('R2 from sklearn:', r2_score(y_true, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9089197e-05\n",
      "6.604814e-05\n",
      "R2 from my own formula: 0.7109805345535278\n"
     ]
    }
   ],
   "source": [
    "# compute R2 by hand. \n",
    "# same results\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "##\n",
    "y_pred = linear_model(X_tensor)\n",
    "y_true = y_tensor\n",
    "after_mse = mse(y_pred, y_true).cpu().detach().numpy()\n",
    "\n",
    "##\n",
    "y_average = y_tensor.mean().repeat(len(y_tensor))\n",
    "before_mse = mse(y_average, y_true).cpu().detach().numpy()\n",
    "\n",
    "## R2\n",
    "print(after_mse)\n",
    "print(before_mse)\n",
    "print('R2 from my own formula:', 1 - after_mse/before_mse) # Hmm...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Linear + Conv to improve R2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spatial autocorrelation should be able to help. But coding needs to be right. \n",
    "- The adjacency matrix is critical. I don't think a fully connected graph can work well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5540883983.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.622404e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.758316e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.983038e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.358477e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  9.622404e+06\n",
       "mean   5.758316e+02\n",
       "std    2.983038e+04\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    1.000000e+00\n",
       "75%    2.600000e+01\n",
       "max    2.358477e+07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the weighted adjacency matrix\n",
    "A_weighted_array = A_weighted_place.toarray()\n",
    "print(np.sum(A_weighted_array))\n",
    "pd.DataFrame(A_weighted_array.reshape(-1, 1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of edges in the new adjacency matrix:  2073356.0\n",
      "Num of edges in the initial adjacency matrix:  5290846.0\n",
      "Total number of potential edges:  9622404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a threshold to filter the weighting array.\n",
    "epsilon = 100.0 # you can change it.\n",
    "\n",
    "import copy\n",
    "A_threshold = copy.copy(A_weighted_array)\n",
    "smaller_than_threshold_mask = A_threshold < epsilon\n",
    "A_threshold[smaller_than_threshold_mask] = 0.0\n",
    "larger_than_threshold_mask = A_threshold > epsilon\n",
    "A_threshold[larger_than_threshold_mask] = 1.0\n",
    "\n",
    "print(\"Num of edges in the new adjacency matrix: \", np.sum(A_threshold))\n",
    "print(\"Num of edges in the initial adjacency matrix: \", np.sum(A_place))\n",
    "print(\"Total number of potential edges: \", A_place.shape[0]*A_place.shape[1])\n",
    "\n",
    "# Q: what is the right density in a graph?\n",
    "\n",
    "A_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# remove self loop.\n",
    "print(np.sum(np.diagonal(A_threshold))) # ! Many self-loops do not reach the threshold!\n",
    "np.fill_diagonal(A_threshold, 0.0)\n",
    "print(np.sum(np.diagonal(A_threshold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3102, 8])\n",
      "torch.Size([3102, 1])\n"
     ]
    }
   ],
   "source": [
    "# input x and y.\n",
    "input_vars = ['pop_total', 'property_value_median', \n",
    "              'households', 'race_white_ratio', 'race_black_ratio', 'age_median', \n",
    "              'travel_driving_ratio', 'edu_bachelor_ratio']\n",
    "\n",
    "# specify X and y\n",
    "X = normalize(X_place[input_vars].values, axis = 0)\n",
    "\n",
    "output_var = 'inc_per_capita'\n",
    "y = normalize(X_place[output_var].values.reshape(-1, 1), axis = 0).reshape(-1,1)\n",
    "\n",
    "# change types of X and y.\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# X and y tensor\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "\n",
    "print(X_tensor.size())\n",
    "print(y_tensor.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436128\n",
      "1436128\n",
      "1436128\n",
      "Number of self-loops is:  0\n"
     ]
    }
   ],
   "source": [
    "# Use the scipy crs to get the list of (row, col) indicators.\n",
    "row_idx = csr_matrix(A_threshold).tocoo().row\n",
    "col_idx = csr_matrix(A_threshold).tocoo().col\n",
    "data_idx = csr_matrix(A_threshold).tocoo().data\n",
    "\n",
    "print(len(data_idx))\n",
    "print(len(col_idx))\n",
    "print(len(row_idx))\n",
    "\n",
    "# test self loops\n",
    "count = 0\n",
    "for i in range(len(col_idx)):\n",
    "    if col_idx[i] == row_idx[i]:\n",
    "        count += 1\n",
    "print(\"Number of self-loops is: \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3102, 8], edge_index=[2, 2872256], y=[3102, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the data object\n",
    "edge_index = torch.tensor([list(row_idx)+list(col_idx), list(col_idx)+list(row_idx)], dtype = torch.long)\n",
    "data = Data(edge_index=edge_index, x = X_tensor, y = y_tensor)\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# check the properties of the data\n",
    "print(data.is_undirected())\n",
    "print(data.has_self_loops())\n",
    "print(data.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, Linear, GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with the simplest case.\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 1, bias = True)\n",
    "        self.lin1 = Linear(-1, 1, bias = True)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "#         self.conv2 = GCNConv(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "#         x = self.lin1(x)\n",
    "        x = self.conv1(x, edge_index) + self.lin1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.lin1 = Linear(-1, hidden_channels)\n",
    "        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n",
    "        self.lin2 = Linear(-1, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.conv1(data.x, data.edge_index) + self.lin1(data.x) # Hmm, add linear here! Consider using it for your naive GNN.\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, data.edge_index) + self.lin2(data.x)\n",
    "        return x\n",
    "\n",
    "# model = GAT(hidden_channels=64, out_channels=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# model_GAT = GAT(hidden_channels=64, out_channels=1).to(device)\n",
    "model_GCN = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model_GCN.parameters(), lr=0.01, weight_decay=9e-6)\n",
    "# optimizer = torch.optim.Adam(model_GAT.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0952, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.3758e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.3001e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.5425e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.2259e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.0356e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.8873e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.7615e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.6529e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.5585e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.4764e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.4050e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.3430e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.2892e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.2427e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.2025e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.1677e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.1377e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.1117e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0891e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0695e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0524e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0376e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0246e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0132e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0033e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9946e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9870e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9805e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9748e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9698e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9655e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9619e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9587e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9560e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9537e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9517e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9501e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9487e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9475e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9465e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9457e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9450e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9444e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9439e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9435e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9431e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9428e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9426e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9424e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9422e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9421e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9420e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9419e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9419e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9418e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9418e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9436e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9429e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9459e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9424e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.1330e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9435e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9531e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9417e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9416e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model_GCN.train()\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model_GCN(data)\n",
    "    loss = F.mse_loss(out, data.y)\n",
    "#     print(loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 from sklearn: 0.7060304306113402\n"
     ]
    }
   ],
   "source": [
    "# compute R2\n",
    "# Hmm...low R2.\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model_GCN(data).cpu().detach().numpy()\n",
    "y_true = y_tensor.cpu().numpy()\n",
    "print('R2 from sklearn:', r2_score(y_true, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive GAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_GAT = GAT(hidden_channels=64, out_channels=1).to(device)\n",
    "# model_GCN = GCN().to(device)\n",
    "data = data.to(device)\n",
    "# optimizer = torch.optim.Adam(model_GCN.parameters(), lr=0.01, weight_decay=9e-6)\n",
    "optimizer = torch.optim.Adam(model_GAT.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(8.1024e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.5971e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.3750e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.8449e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.5478e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.3547e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.2226e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.1304e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0655e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0198e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9874e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9642e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9473e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9346e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0739e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9182e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9125e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9078e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.0878e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9004e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8980e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8960e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8931e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8918e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8908e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8899e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.5025e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8894e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8888e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8883e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8879e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8876e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.2516e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8874e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8871e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8869e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8866e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9176e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8868e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8866e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8864e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8862e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.9094e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8866e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8863e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-1e07c141e32f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train GAT\n",
    "model_GAT.train()\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model_GAT(data)\n",
    "    loss = F.mse_loss(out, data.y)\n",
    "#     print(loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 from sklearn: 0.7144131769427193\n"
     ]
    }
   ],
   "source": [
    "# compute R2\n",
    "# slightly better\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model_GAT(data).cpu().detach().numpy()\n",
    "y_true = y_tensor.cpu().numpy()\n",
    "print('R2 from sklearn:', r2_score(y_true, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
